{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQeIo21Kk9rq2RQaxw8OoV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anderson-Andre-P/Summary-Generator-With-Python-and-NLTK/blob/main/SummarizerAlgorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install reportlab\n",
        "!pip install rouge\n",
        "\n",
        "from google.colab import files\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import heapq\n",
        "import re\n",
        "import io\n",
        "from reportlab.pdfgen import canvas\n",
        "import textwrap\n",
        "from PyPDF2 import PdfReader\n",
        "from rouge import Rouge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHtvj4k9UVGw",
        "outputId": "93232a25-47b1-4e6f-c3b4-d02f01601793"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (4.0.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Summarizer:\n",
        "    def __init__(self, pdf_file_path, language='english', summary_quality=5):\n",
        "        nltk.download('punkt')\n",
        "        nltk.download('stopwords')\n",
        "        self.pdf_file_path = pdf_file_path\n",
        "        self.language = language\n",
        "        self.summary_quality = summary_quality\n",
        "        self.pdf_text = self.extract_text_from_pdf()\n",
        "        self.stop_words = set(stopwords.words(self.language))\n",
        "\n",
        "    def extract_text_from_pdf(self):\n",
        "        pdf_text = \"\"\n",
        "        pdf_reader = PdfReader(self.pdf_file_path)\n",
        "        for page in pdf_reader.pages:\n",
        "            pdf_text += page.extract_text()\n",
        "        return ' '.join(pdf_text.split())\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        text = re.sub(r'[0-9]', ' ', text)\n",
        "        return re.sub(r' +', ' ', text)\n",
        "\n",
        "    def tokenize_and_filter_words(self, text):\n",
        "        words = word_tokenize(text.lower())\n",
        "        return [word for word in words if word not in self.stop_words and word.isalpha()]\n",
        "\n",
        "    def stem_words(self, words):\n",
        "        ps = PorterStemmer()\n",
        "        return [ps.stem(word) for word in words]\n",
        "\n",
        "    def calculate_word_frequency(self, words):\n",
        "        return nltk.FreqDist(words)\n",
        "\n",
        "    def calculate_sentence_scores(self, sentences, word_freq):\n",
        "        scores = {}\n",
        "        for sentence in sentences:\n",
        "            for word in word_tokenize(sentence.lower()):\n",
        "                if word in self.words_without_stopwords:\n",
        "                    if sentence not in scores:\n",
        "                        scores[sentence] = word_freq[word]\n",
        "                    else:\n",
        "                        scores[sentence] += word_freq[word]\n",
        "        return scores\n",
        "\n",
        "    def summarize(self):\n",
        "        self.pdf_text = self.preprocess_text(self.pdf_text)\n",
        "        self.words_without_stopwords = self.tokenize_and_filter_words(self.pdf_text)\n",
        "        self.stemmed_words = self.stem_words(self.words_without_stopwords)\n",
        "        self.word_frequency = self.calculate_word_frequency(self.stemmed_words)\n",
        "        self.sentence_scores = self.calculate_sentence_scores(sent_tokenize(self.pdf_text), self.word_frequency)\n",
        "        best_sentences = heapq.nlargest(self.summary_quality, self.sentence_scores, key=self.sentence_scores.get)\n",
        "        summary = ' '.join(best_sentences)\n",
        "        return summary\n",
        "\n",
        "def add_line_breaks(text, characters_per_line=75):\n",
        "    lines = textwrap.wrap(text, characters_per_line)\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def create_pdf(summary, pdf_file_path, characters_per_line=70):\n",
        "    buffer = io.BytesIO()\n",
        "    pdf_canvas = canvas.Canvas(buffer)\n",
        "\n",
        "    summary_pages = textwrap.wrap(summary, characters_per_line)\n",
        "\n",
        "    x, y = 100, 750\n",
        "\n",
        "    for page_index, page in enumerate(summary_pages):\n",
        "        pdf_canvas.drawString(x, y, page)\n",
        "        y -= 15\n",
        "        if page_index < len(summary_pages) - 1 and y <= 100:\n",
        "            pdf_canvas.showPage()\n",
        "            y = 750\n",
        "\n",
        "    pdf_canvas.save()\n",
        "\n",
        "    with open(\"generated_summary.pdf\", \"wb\") as output_file:\n",
        "        output_file.write(buffer.getvalue())\n",
        "\n",
        "    return \"generated_summary.pdf\"\n",
        "\n",
        "# def calculate_rouge(summary):\n",
        "#     rouge = Rouge()\n",
        "#     scores = rouge.get_scores(summary, summary)\n",
        "#     return scores[0]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pdf_file_path = upload_file()\n",
        "    if pdf_file_path:\n",
        "        language = input(\"Enter the language for the summary (default is 'english'): \")\n",
        "        summary_quality = int(input(\"Enter the quality of the summary (number of sentences): \"))\n",
        "        summarizer = Summarizer(pdf_file_path, language=language, summary_quality=summary_quality)\n",
        "        summary = summarizer.summarize()\n",
        "        summary_with_line_breaks = add_line_breaks(summary)\n",
        "        pdf_path = create_pdf(summary_with_line_breaks, pdf_file_path)\n",
        "        print(\"Summary: \", summary)\n",
        "        print(\"Generated PDF: \", pdf_path)\n",
        "\n",
        "        # rouge_scores = calculate_rouge(summary)\n",
        "        # print(\"ROUGE Scores:\")\n",
        "        # print(\"ROUGE-1: \", rouge_scores['rouge-1']['f'])\n",
        "        # print(\"ROUGE-2: \", rouge_scores['rouge-2']['f'])\n",
        "        # print(\"ROUGE-L: \", rouge_scores['rouge-l']['f'])\n",
        "    else:\n",
        "        print(\"No file uploaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "AXDqP58FUxkx",
        "outputId": "fd48f20c-74fb-4100-c9ba-5633c292b297"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-142c96bd-5ce1-4d60-97c2-1a7da243933c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-142c96bd-5ce1-4d60-97c2-1a7da243933c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving article.pdf to article.pdf\n",
            "Enter the language for the summary (default is 'english'): portuguese\n",
            "Enter the quality of the summary (number of sentences): 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:  Nome Anderson André Pereira Eleutério RA Introdução Segundo Fadel e Silveira as metodologias ágeis são muito utilizadas por empresas desenvolvedoras de software que visam administrar melhor seus recursos e o tempo disponível para desenvolvimento das atividades Um dos objetivos que as organizações têm ao utilizar as metodologias ágeis é melhorar o fluxo do desenvolvimento de software alocando menos recursos na produção e aumentando a eficiência das equipes isso melhora a qualidade dos produtos desenvolvidos Os mesmos autores informam que o um encontro realizado por desenvolvedores de software identificou princípios e premissas que estão presentes no manifesto ágil As premissas podem ser representados nos seguintes tópicos Valorizar pessoas e interações acima de processos e ferramentas Priorizar o software funcional em vez de documentação detalhada Dar importância à colaboração com o cliente em vez de negociação de contratos Ser adaptável às mudanças em vez de seguir um plano inicial rigidamente Os princípios de acordo com Beck et al que foram citadas anteriormente podem ser representadas pelos seguintes pontos A prioridade é satisfazer o cliente entregando software com valor agregado de forma contínua e adiantada As mudanças nos requisitos são bemvindas mesmo em estágios avançados de desenvolvimento Processos ágeis aproveitam essas mudanças para proporcionar vantagem competitiva ao cliente Entregas frequentes de software funcional em períodos de poucas semanas a poucos meses com preferência para intervalos menores As pessoas de negócio e desenvolvedores devem trabalhar juntos diariamente durante todo o projeto Os projetos devem ser construídos em torno de indivíduos motivados com ambiente e suporte adequados e confiança para fazer o trabalho A melhor forma de transmitir informações para e entre equipes de desenvolvimento é por meio de conversas face a face Software funcionando é a medida primária de progresso Processos ágeis promovem desenvolvimento sustentável permitindo que patrocinadores desenvolvedores e usuários mantenham um ritmo constante indefinidamente A atenção contínua à excelência técnica e ao bom design aumenta a agilidade A simplicidade é essencial para maximizar a quantidade de trabalho não realizado As melhores arquiteturas requisitos e designs emergem de equipes autoorganizáveis A equipe deve refletir regularmente sobre como se tornar mais eficaz e ajustar seu comportamento de acordo Scrum Fadel e Silveira diz que no Scrum não é definida nenhuma técnica para o desenvolvimento de software durante sua implementação na verdade ele se concentra em descrever como cada membro da equipe deve se comportar durante o trabalho para se tornar flexível já que o ambiente é repleto de mudanças frequentes Filho D L B diz que o Scrum possui alguns elementos de apoio como product backlog backlog selecionado sprint backlog backlog de impedimentos e gráficos de suporte Para uma melhor organização Filho D L B informa que dentro do Scrum são definidos alguns papéis e responsabilidades que são atreladas a cada indivíduo que esteja envolvido no trabalho alguns exemplos são cliente gerente equipe Scrum Scrum Master e o responsável pelo produto Fadel e Silveira ainda diz que a metodologia ágil Scrum tem um processo que busca realizar entregas de maneira contínua onde cada entrega é definida pelo product backlog e as entregas são realizadas em ciclos de sprint que são os prazospré determinados para entregar as atividades Além disso cada sprint possui reuniões diárias de até minutos e uma reunião final quando cada sprint é finalizado O processo do Scrum pode ser observado na figura Figura Ciclo do Scrum Fonte httpswwwwrikecomscrumguidescrumsprints FADEL Aline SILVEIRA Henrique Metodologias ágeis no contexto de desenvolvimento de so ware XP Scrum e Lean Academia Accelerating the worlds research cesetunicampbr BECK K et al Manifesto for Agile Software Development Disponível em httpwww agilemanifestooorg Acesso em Março de FILHO D L B Experiências com desenvolvimento ágil Instituto de Matemática e Estatística da Universidade de São Paulo Dissertação de Mestrado Guide to Scrum Sprints Wrike Scrum Guide Disponível em httpswww wrikecomscrumguidescrumsprints Acesso em de março de\n",
            "Generated PDF:  generated_summary.pdf\n",
            "ROUGE Scores:\n",
            "ROUGE-1:  0.999999995\n",
            "ROUGE-2:  0.999999995\n",
            "ROUGE-L:  0.999999995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSBn5dC9PYCu"
      },
      "outputs": [],
      "source": [
        "# class Summarizer:\n",
        "#     def __init__(self, pdf_file_path, language='english', summary_quality=5):\n",
        "#         nltk.download('punkt')\n",
        "#         nltk.download('stopwords')\n",
        "#         self.pdf_file_path = pdf_file_path\n",
        "#         self.language = language\n",
        "#         self.summary_quality = summary_quality\n",
        "#         self.pdf_text = self.extract_text_from_pdf()\n",
        "#         self.stop_words = set(stopwords.words(self.language))\n",
        "\n",
        "\n",
        "#     def extract_text_from_pdf(self):\n",
        "#         pdf_text = \"\"\n",
        "#         reader = PdfReader(self.pdf_file_path)\n",
        "#         for page in reader.pages:\n",
        "#             pdf_text += page.extract_text()\n",
        "#         return ' '.join(pdf_text.split())\n",
        "\n",
        "#     def preprocess_text(self, text):\n",
        "#         text = re.sub(r'[^\\w\\s]', '', text)\n",
        "#         text = re.sub(r'[0-9]', ' ', text)\n",
        "#         return re.sub(r' +', ' ', text)\n",
        "\n",
        "#     def tokenize_and_filter_words(self, text):\n",
        "#         palavras = word_tokenize(text.lower())\n",
        "#         return [palavra for palavra in palavras if palavra not in self.stop_words and palavra.isalpha()]\n",
        "\n",
        "#     def stem_words(self, words):\n",
        "#         ps = PorterStemmer()\n",
        "#         return [ps.stem(palavra) for palavra in words]\n",
        "\n",
        "#     def calculate_word_frequency(self, words):\n",
        "#         return nltk.FreqDist(words)\n",
        "\n",
        "#     def calculate_sentence_scores(self, sentences, word_freq):\n",
        "#         scores = {}\n",
        "#         for sentenca in sentences:\n",
        "#             for palavra in word_tokenize(sentenca.lower()):\n",
        "#                 if palavra in self.palavras_sem_stopwords:\n",
        "#                     if sentenca not in scores:\n",
        "#                         scores[sentenca] = word_freq[palavra]\n",
        "#                     else:\n",
        "#                         scores[sentenca] += word_freq[palavra]\n",
        "#         return scores\n",
        "\n",
        "#     def summarize(self):\n",
        "#         self.pdf_text = self.preprocess_text(self.pdf_text)\n",
        "#         self.palavras_sem_stopwords = self.tokenize_and_filter_words(self.pdf_text)\n",
        "#         self.palavras_stemmed = self.stem_words(self.palavras_sem_stopwords)\n",
        "#         self.frequencia_palavras = self.calculate_word_frequency(self.palavras_stemmed)\n",
        "#         self.pontuacao_sentencas = self.calculate_sentence_scores(sent_tokenize(self.pdf_text), self.frequencia_palavras)\n",
        "#         melhores_sentencas = heapq.nlargest(self.summary_quality, self.pontuacao_sentencas, key=self.pontuacao_sentencas.get)\n",
        "#         resumo = ' '.join(melhores_sentencas)\n",
        "#         return resumo\n",
        "\n",
        "\n",
        "# def adicionar_quebras_de_linha(texto, caracteres_por_linha=75):\n",
        "#     linhas = textwrap.wrap(texto, caracteres_por_linha)\n",
        "#     return \"\\n\".join(linhas)\n",
        "\n",
        "# def criar_pdf(resumo, arquivo_pdf_path, caracteres_por_linha=70):\n",
        "#     buffer = io.BytesIO()\n",
        "#     pdf_canvas = canvas.Canvas(buffer)\n",
        "\n",
        "#     paginas_do_resumo = textwrap.wrap(resumo, caracteres_por_linha)\n",
        "\n",
        "#     x, y = 100, 750\n",
        "\n",
        "#     for indice_pagina, pagina in enumerate(paginas_do_resumo):\n",
        "#         pdf_canvas.drawString(x, y, pagina)\n",
        "#         y -= 15  # ajusta a posição da próxima linha\n",
        "#         if indice_pagina < len(paginas_do_resumo) - 1 and y <= 100:\n",
        "#             pdf_canvas.showPage()\n",
        "#             y = 750\n",
        "\n",
        "#     pdf_canvas.save()\n",
        "\n",
        "#     with open(\"resumo_gerado.pdf\", \"wb\") as output_file:\n",
        "#         output_file.write(buffer.getvalue())\n",
        "\n",
        "#     return \"resumo_gerado.pdf\"\n",
        "\n",
        "\n",
        "# def upload_file():\n",
        "#     uploaded = files.upload()\n",
        "#     if len(uploaded) > 0:\n",
        "#         return list(uploaded.keys())[0]\n",
        "#     else:\n",
        "#         return None\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     pdf_file_path = upload_file()\n",
        "#     if pdf_file_path:\n",
        "#         language = input(\"Enter the language for the summary (default is 'english'): \")\n",
        "#         summary_quality = int(input(\"Enter the quality of the summary (number of sentences): \"))\n",
        "#         summarizer = Summarizer(pdf_file_path, language=language, summary_quality=summary_quality)\n",
        "#         resumo = summarizer.summarize()\n",
        "#         resumo_com_quebras = adicionar_quebras_de_linha(resumo)\n",
        "#         pdf_path = criar_pdf(resumo_com_quebras, pdf_file_path)\n",
        "#         print(\"Resumo: \", resumo)\n",
        "#         print(\"PDF gerado: \", pdf_path)\n",
        "#     else:\n",
        "#         print(\"Nenhum arquivo enviado.\")"
      ]
    }
  ]
}